{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Básicas\n",
    "\n",
    "Neste notebook, vamos aprender sobre redes neurais artificiais, os blocos fundamentais do Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que são Redes Neurais?\n",
    "\n",
    "Redes neurais artificiais são modelos computacionais inspirados no funcionamento do cérebro humano. Elas consistem em:\n",
    "\n",
    "- **Neurônios**: Unidades básicas de processamento\n",
    "- **Camadas**: Conjuntos de neurônios organizados\n",
    "- **Pesos**: Valores que determinam a importância das conexões\n",
    "- **Função de Ativação**: Introduz não-linearidade no modelo\n",
    "\n",
    "### Arquitetura Básica:\n",
    "\n",
    "1. **Camada de Entrada**: Recebe os dados\n",
    "2. **Camadas Ocultas**: Processam a informação\n",
    "3. **Camada de Saída**: Produz o resultado final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron: A Rede Neural mais Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"Implementação simples de um Perceptron.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, learning_rate=0.01):\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = 0\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def activation(self, x):\n",
    "        \"\"\"Função de ativação step.\"\"\"\n",
    "        return 1 if x >= 0 else 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Faz previsões.\"\"\"\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(linear_output)\n",
    "    \n",
    "    def train(self, X, y, epochs=100):\n",
    "        \"\"\"Treina o perceptron.\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            for xi, target in zip(X, y):\n",
    "                prediction = self.predict(xi)\n",
    "                error = target - prediction\n",
    "                \n",
    "                # Atualiza pesos e bias\n",
    "                self.weights += self.learning_rate * error * xi\n",
    "                self.bias += self.learning_rate * error\n",
    "\n",
    "print(\"Classe Perceptron definida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Ativação Comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Função Sigmoid: mapeia valores para (0, 1).\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU (Rectified Linear Unit): max(0, x).\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\"Tangente hiperbólica: mapeia valores para (-1, 1).\"\"\"\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Visualizando as funções de ativação\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.title('Sigmoid')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(x, relu(x))\n",
    "plt.title('ReLU')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(x, tanh(x))\n",
    "plt.title('Tanh')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Prático com TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação do TensorFlow (descomente para executar)\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=42)\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Visualizando os dados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='Classe 0', alpha=0.5)\n",
    "plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='Classe 1', alpha=0.5)\n",
    "plt.title('Dataset Moons')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo uma rede neural com Keras\n",
    "try:\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    # Definindo o modelo\n",
    "    modelo = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(2,)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    modelo.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Resumo do modelo\n",
    "    modelo.summary()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"TensorFlow não está instalado. Execute a célula anterior para instalar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "try:\n",
    "    history = modelo.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento concluído!\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"Modelo não foi definido. Certifique-se de que o TensorFlow está instalado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o treinamento\n",
    "try:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['loss'], label='Treino')\n",
    "    plt.plot(history.history['val_loss'], label='Validação')\n",
    "    plt.title('Perda durante o Treinamento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['accuracy'], label='Treino')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validação')\n",
    "    plt.title('Acurácia durante o Treinamento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except NameError:\n",
    "    print(\"História do treinamento não disponível.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo\n",
    "try:\n",
    "    test_loss, test_acc = modelo.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Acurácia no conjunto de teste: {test_acc:.2%}\")\n",
    "    print(f\"Perda no conjunto de teste: {test_loss:.4f}\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"Modelo não foi treinado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos Importantes\n",
    "\n",
    "### Hiperparâmetros\n",
    "- **Learning Rate**: Taxa de aprendizado\n",
    "- **Batch Size**: Tamanho do lote\n",
    "- **Epochs**: Número de iterações sobre todo o dataset\n",
    "- **Número de Camadas**: Profundidade da rede\n",
    "- **Número de Neurônios**: Largura de cada camada\n",
    "\n",
    "### Otimizadores Comuns\n",
    "- **SGD**: Stochastic Gradient Descent\n",
    "- **Adam**: Adaptive Moment Estimation\n",
    "- **RMSprop**: Root Mean Square Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "1. Modifique a arquitetura da rede (adicione mais camadas ou neurônios) e observe o impacto na performance\n",
    "2. Experimente diferentes funções de ativação (relu, tanh, sigmoid)\n",
    "3. Ajuste a taxa de aprendizado e compare os resultados\n",
    "4. Implemente early stopping para evitar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
