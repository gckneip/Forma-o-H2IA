{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto: Classificação de Dados End-to-End\n",
    "\n",
    "Neste projeto prático, você irá desenvolver um pipeline completo de Machine Learning, desde a coleta de dados até a avaliação do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo do Projeto\n",
    "\n",
    "Criar um modelo de classificação para prever se um cliente irá comprar um produto com base em suas características demográficas e comportamentais.\n",
    "\n",
    "## Etapas do Projeto\n",
    "\n",
    "1. Importação e exploração de dados\n",
    "2. Análise exploratória de dados (EDA)\n",
    "3. Pré-processamento e feature engineering\n",
    "4. Divisão dos dados\n",
    "5. Treinamento de múltiplos modelos\n",
    "6. Avaliação e comparação de modelos\n",
    "7. Otimização de hiperparâmetros\n",
    "8. Validação final\n",
    "9. Interpretação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Geração e Exploração de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um dataset sintético para o projeto\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "dados = pd.DataFrame({\n",
    "    'idade': np.random.randint(18, 70, n_samples),\n",
    "    'salario': np.random.randint(20000, 150000, n_samples),\n",
    "    'tempo_site': np.random.randint(1, 100, n_samples),\n",
    "    'paginas_visitadas': np.random.randint(1, 50, n_samples),\n",
    "    'genero': np.random.choice(['M', 'F'], n_samples),\n",
    "    'pais': np.random.choice(['Brasil', 'EUA', 'Canada', 'Reino Unido'], n_samples),\n",
    "})\n",
    "\n",
    "# Criando a variável alvo com alguma lógica\n",
    "dados['comprou'] = ((dados['tempo_site'] > 30) & (dados['salario'] > 60000)).astype(int)\n",
    "\n",
    "# Adicionando algum ruído\n",
    "noise_indices = np.random.choice(dados.index, size=int(0.1 * len(dados)), replace=False)\n",
    "dados.loc[noise_indices, 'comprou'] = 1 - dados.loc[noise_indices, 'comprou']\n",
    "\n",
    "print(\"Dataset criado com sucesso!\")\n",
    "print(f\"\\nShape: {dados.shape}\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações básicas\n",
    "print(\"Informações do Dataset:\")\n",
    "print(dados.info())\n",
    "\n",
    "print(\"\\nEstatísticas Descritivas:\")\n",
    "print(dados.describe())\n",
    "\n",
    "print(\"\\nValores Ausentes:\")\n",
    "print(dados.isnull().sum())\n",
    "\n",
    "print(\"\\nDistribuição da Variável Alvo:\")\n",
    "print(dados['comprou'].value_counts())\n",
    "print(f\"\\nPercentual de compradores: {dados['comprou'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Distribuição de idade\n",
    "dados['idade'].hist(ax=axes[0, 0], bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Distribuição de Idade')\n",
    "\n",
    "# Distribuição de salário\n",
    "dados['salario'].hist(ax=axes[0, 1], bins=20, edgecolor='black')\n",
    "axes[0, 1].set_title('Distribuição de Salário')\n",
    "\n",
    "# Tempo no site\n",
    "dados['tempo_site'].hist(ax=axes[0, 2], bins=20, edgecolor='black')\n",
    "axes[0, 2].set_title('Tempo no Site')\n",
    "\n",
    "# Distribuição por gênero\n",
    "dados['genero'].value_counts().plot(kind='bar', ax=axes[1, 0], edgecolor='black')\n",
    "axes[1, 0].set_title('Distribuição por Gênero')\n",
    "\n",
    "# Distribuição por país\n",
    "dados['pais'].value_counts().plot(kind='bar', ax=axes[1, 1], edgecolor='black')\n",
    "axes[1, 1].set_title('Distribuição por País')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Distribuição da variável alvo\n",
    "dados['comprou'].value_counts().plot(kind='bar', ax=axes[1, 2], edgecolor='black')\n",
    "axes[1, 2].set_title('Distribuição: Comprou?')\n",
    "axes[1, 2].set_xticklabels(['Não', 'Sim'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando variáveis categóricas\n",
    "dados_processados = dados.copy()\n",
    "\n",
    "# One-hot encoding para 'genero' e 'pais'\n",
    "dados_processados = pd.get_dummies(dados_processados, columns=['genero', 'pais'], drop_first=True)\n",
    "\n",
    "print(\"Dados após pré-processamento:\")\n",
    "print(dados_processados.head())\n",
    "print(f\"\\nNovas features: {dados_processados.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Divisão dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features e target\n",
    "X = dados_processados.drop('comprou', axis=1)\n",
    "y = dados_processados['comprou']\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
    "print(f\"\\nDistribuição no treino: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuição no teste: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinamento de Múltiplos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos\n",
    "modelos = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Treinando e avaliando cada modelo\n",
    "resultados = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\nTreinando {nome}...\")\n",
    "    modelo.fit(X_train_scaled, y_train)\n",
    "    y_pred = modelo.predict(X_test_scaled)\n",
    "    y_pred_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculando métricas\n",
    "    resultados[nome] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"Acurácia: {resultados[nome]['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {resultados[nome]['precision']:.4f}\")\n",
    "    print(f\"Recall: {resultados[nome]['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {resultados[nome]['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC: {resultados[nome]['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nTreinamento de todos os modelos concluído!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando DataFrame com resultados\n",
    "df_resultados = pd.DataFrame(resultados).T\n",
    "print(\"Comparação de Modelos:\")\n",
    "print(df_resultados.sort_values('accuracy', ascending=False))\n",
    "\n",
    "# Visualizando a comparação\n",
    "df_resultados.plot(kind='bar', figsize=(14, 6))\n",
    "plt.title('Comparação de Métricas entre Modelos')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sua Vez!\n",
    "\n",
    "### Tarefas a Completar:\n",
    "\n",
    "1. **Feature Engineering**: Crie novas features (ex: salario_por_idade, interacao_tempo_paginas)\n",
    "2. **Otimização**: Use GridSearchCV para otimizar hiperparâmetros do melhor modelo\n",
    "3. **Análise de Erros**: Analise os casos em que o modelo errou\n",
    "4. **Interpretação**: Use feature importance para entender quais variáveis são mais importantes\n",
    "5. **Curva ROC**: Plote a curva ROC para o melhor modelo\n",
    "\n",
    "### Espaço para seu código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
