{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Machine Learning\n",
    "\n",
    "Este notebook apresenta os conceitos fundamentais de Machine Learning (Aprendizado de Máquina) e implementa um exemplo prático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Machine Learning?\n",
    "\n",
    "Machine Learning é uma área da Inteligência Artificial que permite que computadores aprendam a partir de dados, sem serem explicitamente programados.\n",
    "\n",
    "### Tipos de Aprendizado:\n",
    "\n",
    "1. **Aprendizado Supervisionado**: O modelo aprende com dados rotulados\n",
    "   - Classificação: Prever categorias (ex: spam ou não spam)\n",
    "   - Regressão: Prever valores contínuos (ex: preço de uma casa)\n",
    "\n",
    "2. **Aprendizado Não Supervisionado**: O modelo encontra padrões em dados não rotulados\n",
    "   - Clustering: Agrupar dados similares\n",
    "   - Redução de dimensionalidade: Simplificar dados complexos\n",
    "\n",
    "3. **Aprendizado por Reforço**: O modelo aprende através de tentativa e erro com recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de Machine Learning\n",
    "\n",
    "Um projeto típico de ML segue estas etapas:\n",
    "\n",
    "1. **Coleta de Dados**: Obter dados relevantes\n",
    "2. **Exploração**: Entender os dados (EDA)\n",
    "3. **Pré-processamento**: Limpar e preparar os dados\n",
    "4. **Divisão**: Separar em treino e teste\n",
    "5. **Treinamento**: Treinar o modelo\n",
    "6. **Avaliação**: Medir a performance\n",
    "7. **Otimização**: Melhorar o modelo\n",
    "8. **Deploy**: Colocar em produção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Prático: Classificação Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gerando dados sintéticos\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Shape dos dados: {X.shape}\")\n",
    "print(f\"Shape dos labels: {y.shape}\")\n",
    "print(f\"Distribuição das classes: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Divisão em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Média antes da normalização:\", X_train[:, 0].mean())\n",
    "print(\"Média depois da normalização:\", X_train_scaled[:, 0].mean())\n",
    "print(\"Desvio padrão depois da normalização:\", X_train_scaled[:, 0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Treinamento do modelo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modelo treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fazendo previsões\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "\n",
    "print(\"Primeiras 10 previsões:\", y_pred[:10])\n",
    "print(\"Primeiros 10 valores reais:\", y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Avaliando o modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {acuracia:.2%}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Matriz de Confusão\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos Importantes\n",
    "\n",
    "### Overfitting vs Underfitting\n",
    "\n",
    "- **Overfitting**: Modelo memoriza os dados de treino e não generaliza bem\n",
    "- **Underfitting**: Modelo é muito simples e não captura padrões importantes\n",
    "\n",
    "### Validação Cruzada\n",
    "\n",
    "Técnica para avaliar o modelo de forma mais robusta, dividindo os dados em múltiplos folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de validação cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(modelo, X_train_scaled, y_train, cv=5)\n",
    "print(f\"Scores de validação cruzada: {scores}\")\n",
    "print(f\"Média: {scores.mean():.2%}\")\n",
    "print(f\"Desvio padrão: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "1. Experimente diferentes proporções de divisão treino/teste (70/30, 80/20, 90/10) e compare os resultados\n",
    "2. Tente treinar o modelo sem normalizar os dados e compare a performance\n",
    "3. Pesquise e implemente outro algoritmo de classificação (ex: Decision Tree, Random Forest)\n",
    "4. Calcule outras métricas como precision, recall e F1-score manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
